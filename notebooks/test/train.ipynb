{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axc_ZAFUykIY"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Masao-Taketani/JPN-EN-Transformer-translator/blob/master/notebooks/test/train.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4v1DluS6axM",
        "outputId": "3d5e7a59-cb61-42ad-8d91-5907f1c65b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6zx8Eaa7-FV",
        "outputId": "8161a100-02c5-4deb-9cf5-0aaef538a10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmeCRYnj6EDe"
      },
      "source": [
        "import sentencepiece as spm\n",
        "import tensorflow as tf\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoZWq4ucyf1J",
        "outputId": "07336a11-223b-4655-9c95-bbe72927dc75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64\n",
        "jpn_sp_model = \"drive/My Drive/deep_learning_models/JPN-EN-Transformer-translator/jpn_spm.model\"\n",
        "en_sp_model = \"drive/My Drive/deep_learning_models/JPN-EN-Transformer-translator/en_spm.model\"\n",
        "jpn_sp = spm.SentencePieceProcessor()\n",
        "en_sp = spm.SentencePieceProcessor()\n",
        "jpn_sp.Load(jpn_sp_model)\n",
        "en_sp.Load(en_sp_model)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcHSUcptE3xv"
      },
      "source": [
        "def read_data(fpath):\n",
        "  with open(fpath, \"r\") as f:\n",
        "    return f.read()\n",
        "\n",
        "def get_data(fpath):\n",
        "  data = read_data(fpath)\n",
        "  data_list = []\n",
        "  for line in data.split(\"\\n\"):\n",
        "    data_list.append(line)\n",
        "  return data_list\n",
        "\n",
        "def get_max_len_and_list(fpath):\n",
        "  data = read_data(fpath)\n",
        "  max_len = 0\n",
        "  li = []\n",
        "  for line in data.split(\"\\n\"):\n",
        "    li.append(line)\n",
        "    if max_len < len(line):\n",
        "      max_len = len(line)\n",
        "  return max_len, li\n",
        "\n",
        "def get_max_len(data_list):\n",
        "  max_len = 0\n",
        "  for d in data_list:\n",
        "    data_length = len(d)\n",
        "    if data_length > max_len:\n",
        "      max_len = data_length\n",
        "  return max_len"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9sc8oKBFGFf",
        "outputId": "4eb281c9-3645-4168-e54c-ac46edffebf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "jpn_path = \"drive/My Drive/deep_learning_models/JPN-EN-Transformer-translator/jpn_data.txt\"\n",
        "en_path = \"drive/My Drive/deep_learning_models/JPN-EN-Transformer-translator/en_data.txt\"\n",
        "jpn_data = get_data(jpn_path)\n",
        "en_data = get_data(en_path)\n",
        "train_jpn, val_jpn, train_en, val_en = train_test_split(jpn_data, en_data, test_size=0.05)\n",
        "JPN_MAX_LEN = get_max_len(train_jpn)\n",
        "EN_MAX_LEN = get_max_len(train_en)\n",
        "print(\"train size:\", len(train_jpn), \"validation size:\", len(val_jpn),\"\\n\",\n",
        "      \"JPN_MAX_LEN:\", JPN_MAX_LEN, \"EN_MAX_LEN:\", EN_MAX_LEN)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train size: 142298 validation size: 7490 \n",
            " JPN_MAX_LEN: 117 EN_MAX_LEN: 251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlNX0FOuyywQ"
      },
      "source": [
        "# When you have tf.Tensor(string) and .numpy() method is used inside of the tf.py_function, \n",
        "# it is converted to just a string. Not a numpy.\n",
        "def encode(jpn, en):\n",
        "  jpn_enc = [jpn_sp.PieceToId(\"<s>\")] + jpn_sp.EncodeAsIds(jpn.numpy()) + [jpn_sp.PieceToId(\"</s>\")]\n",
        "  en_enc = [en_sp.PieceToId(\"<s>\")] + en_sp.EncodeAsIds(en.numpy()) + [en_sp.PieceToId(\"</s>\")]\n",
        "  return jpn_enc, en_enc\n",
        "\n",
        "def tf_encode(jpn, en):\n",
        "  result_jpn, result_en = tf.py_function(encode, [jpn, en], [tf.int64, tf.int64])\n",
        "  result_jpn.set_shape([None])\n",
        "  result_en.set_shape([None])\n",
        "  return result_jpn, result_en"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvoBNnYUO4G9"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_jpn, train_en))\n",
        "train_dataset = train_dataset.map(tf_encode)\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_jpn, val_en))\n",
        "val_dataset = val_dataset.map(tf_encode)\n",
        "val_dataset = val_dataset.padded_batch(BATCH_SIZE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hYVybxte6XV"
      },
      "source": [
        "# Positinal Encoding\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array: 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array: 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "  # add the new dim to the first dimension\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6qUqDtyyU6F",
        "outputId": "732f7d97-798d-4e5b-fb75-4ff2920a021c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pos_encoding = positional_encoding(position=50, d_model=512)\n",
        "print(pos_encoding.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 50, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOClKh8o1SWA",
        "outputId": "a01d195a-cbec-4521-d404-9414ea97bda2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.pcolormesh(pos_encoding[0], cmap=\"RdBu\")\n",
        "plt.xlabel(\"Depth\")\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel(\"Position\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5xU1fmHn/femdneKywsvSpSRBCxYe8aE1s0lhhNYokaE2OKJjHFmKIxicaoMZpmjwb8YbCAoiDFQkfaUndh2b47u9PunfP7494ZZpeFHWAXWTzP53Oc2++ZdThz5/ue9/uKUgqNRqPRfD4wPusOaDQajebgoQd9jUaj+RyhB32NRqP5HKEHfY1Go/kcoQd9jUaj+RyhB32NRqP5HNGjg76IbBKR5SKyREQ+dLfli8ibIrLOfc3ryT5oNBrNZ4WIPCUiO0VkxR72i4j8QUTWi8gyEZmQsO8ad5xcJyLXdFefDsaT/jSl1Dil1ER3/W7gbaXUMOBtd12j0WgOR54GztrL/rOBYW67EfgzOA/HwI+BycAk4Mfd9YD8Wcg7FwLPuMvPABd9Bn3QaDSaHkcpNReo38shFwJ/Vw4LgFwR6QOcCbyplKpXSjUAb7L3L4+k8XTHRfaCAt4QEQX8RSn1OFCilNru7t8BlHR2oojciPPNR0Z62tFtKp1xowawZPVmxo0sZ+snKxlwxCCWbGkiIy+Hfi3baWgMUTr+CJat2443LZ0jCk2UbbGmxUNbQx1FfUsoU01Ubawh1RAKRw5kY6vQsLMO0+ujsCiXmuo6VDRKVkE+QwrSCG2toL4ugK0gN91LZnkJbd5sNlW3UJKfTkEKWDU7aN3ZQosVBSDdNMjITSGlqAA7LYfKT1biEyEjxSQ1Nw1vXh7R1CxawjYNrWHaAhZWKIgdCUPUZsKQIqKtzYRb2oi0hgmHo4SiClspooAApoBHhIKyXKxACCtoYYdswtEoVpT4sbF8awPIPmIkYVsRtqKELZuwFSVqK6dFo6io7TZneWypD/F4EdMLhokyTOcVIarAVqCU0681FdsRERBBcF8NY9e6YSBiICJ4U0yUApRCuddw1kE5/yGWKa5UlMysVEQEAQwR3NsgCIbg7HO3VVXWxd+1ci7Q4RO5a33IoD5I7PPm/kfctfbrDqvXb0vmMw/AkcP6d7pdZPdty9dsSfq6AEeNLO/82p1sW/pp8tcet4frdsaSfbiuc+0B+3Dtzclfd1T76y5ZvRkVqKtVShUlfZEOGNn9FFYwqWNVoG4lkHjw4+44lyxlwNaE9W3utj1tP2B6etA/XilVKSLFwJsi8mniTqWUcr8QdsP9wz0OcPRRR6jl5mTmzXuUnCk3Mff9R/hOxigeeekJCm6ZxXFfOof7Z/+MV2as43vz5tH3gvspPeJoFl6fgd1Ux0nvFvDRi//i8nvv4P7wa/z0K08wPNPHtS89wVcWpfLKI0+TWTqQa288lz8/9G8iwVZOuPpSXrrySDbe9hX+9c/lNEWiXDyqlOP++B2Wlp3C1Q+9x51XjOXqwSa1j/2ChX+ay5yaNgAm5KQy+fxhDLnxGlqOPJsfZo+mb4qHKQNzGHHRUfT90pdoHXkK725u4rkPt7JsWTU7N6zFv2MTVtDPohdvpG3hG1S+u4SqxZVs3tLMprYI9WGbcFRhCuR4TQp9JtfcdSG1yzZQt6aWhopGKv1hakI2DRGbgB3Fdv+6PkM4+6U32NIUZFNtK5vrWqmqa6O1OURbU4hgW5hQSyPhtiasgB8r2Mq875RjFpRi5hVDRi7RlCyiablEzBTaIlFaI1EClqI5ZHHK5T/B9PowPD4MjxfD48NMScP0+OLLhseHx+el37ACrHAUK2JjRWxsK4oViRK1oth2FNuKErWj2JZF1Aoz5eQR+DwGPo/pvJoGKR7D3da+3fPjp1FR2/kMuV9ezrLzGnVfAR792w8wBEwRDBFMw/lS6bguAgbC0Rfc1e5ae2PGGw8Buwb52E9qcTcYCSP0gGm3dnm9RN5+90+dDvBGJxuLT7gl6eu++/4j7dY7u0eM/Kk3J31dgPfnPZr0sbnH3ZT0sfM6XDdnyk1Elvwt+W+NzrCCeEZckNShkSV/CyZI172CHpV3lFKV7utO4BUcbara/fmC+7qzJ/ug0Wg0+4QIYphJtW6gEkj8WdjP3ban7QdMjw36IpIhIlmxZeAMYAUwHYhFoq8B/ttTfdBoNJp9R9xfrF23bmA6cLU7i+dYoMmVv2cBZ4hInhvAPcPddsD0pLxTArzi/pz1AP9WSv1PRBYDL4jI9cBm4NIe7INGo9HsG+6TfvdcSp4FTgYKRWQbzowcL4BS6jFgJnAOsB5oA65z99WLyM+Axe6l7lNK7S0gnDQ9NugrpSqAsZ1srwNO3ZdrrdoZZsp3r+adkZOZcuvDLDjmRC4dU8yl851v2unn53HbTav50S/O5ew/LyTYVMvf7ziBOWefQeTl11g281eUTzmPB84czNsjniVgK07/+hQWpo7m3ddfRkVtRp94DC/NXENbXRUDjjufu04bTvTNJ1k6fS01IZsJuamMunQi1rhz+ef/1jF+fB/OGFpAdNG/2fTmSpY3hQhHFf3TvAwemkfZieNg2GRW1QTI9BgMyvBSPKaYwolHoMrHsKU5zEdbG9m4rZnm2gaCDdVYQT8A4YqVNK7dSuPGBhq3+6kJ2fitKOGoI9D7DCHDNMj3mbRW1tK2009bbYCmoIXfitJqO8fG9HxTnNYQiNDQFqauNUydP0woYBEOWIRDFpFgG3Y4gB0KELXCqKiNkZ6FkZqB+NKIelJRvnSUJ4WwpZyAcFQRtqOErChixn7yGohhYnh9GO5PYMPjQwwT0+NBRLBj2r0dRUWdQLKKKqLKeVVKEY2quHZuGoJpGM6riLveSUuIkqpodO+fT9u9dpJ6/q7rdq3n7wudBXb3h870fDmAi3dTt3olAojZPYO+UuqKLvYroNMAiVLqKeCpbulIAj0dyNVoNJrehQhGNz3pH4roQV+j0Wg60F3yzqGIHvQ1Go0mkW7U9A9F9KCv0Wg0CQiC4fF+1t3oMXqFy2aopZG3TwnyxrZmZp9r8srqGo5dOJfXHnmSn//set468csck5dG7bW/ZOFzLzDp0ksYPe8RXlldw+2PfICybe65/hhqH7idmZXNnN0/mz7f/infe3EZtWsXU3zEVO654AgqP55DRlF/zjltKMemN7Ly8ddY3BAkx2swYUoZRRdfyVsbG3l38VYun9ifstaNVL4+m7UraqgOWaSZwuhsH/2OG0jG5FPYYeQyb3M9JSke+g/MpXTiUFLHTKHBV8CS7S18vLmB+u0ttO7cQri1CQDTl0Zw0wYa11fRvK2ZmpBNs+UkWoETxM30GOR43UDujjr81a201QdoikTjAV87IfPUFMFnCPXBCDubQ9T5QwQDEcKBCOGQ5SRIhQJYYSeIG7Ui2JEwRkY2RkYWUV8aUW8aypNCROEEcKMKy4a2iE3QisaDtrEgriQGcc1YMFcwPQYqihOwjSpsO+oGbVU8OUu5QVwVtVG2HQ/U+kwnASuWmNUxkGuItAu07i0xCzoPfu6JfYmJxu6XTGLW/vB5DrIeFA7uPP2Djn7S12g0mg701gE9GfSgr9FoNImIdNuUzUMRPehrNBpNAsLh/aTfKzT9/uV9+OVxt3DvHy/jwYnX893vnsQxP3yTPuNP4/rqV3m1ooEvT/8pF/98NukFfXntm5N57uZ/MjwzhY3vT+eocy/gqvwaZjz8Hvk+kxPvv4RnNipWvv0evowcTj/rSE5Or8UOBxg8eQq3nTCQxmf/xIJ52/BbUY7NT2PUV6ZRlX8kT83fRNXqT5k2MIfA3FfY+NYG1vrD2AoGpvvoP6GUPtOOxRpwNB9VtTBn9U6GZnrpM6EPOePGEelzBOsbgny4uYGqrU207NxO2N9A1AojhokvI4eGtVtp2txMfV0gnpiVaJwWS8xKz0+jZbuftroA9WGbpohN0NXbExOzfIaQZhrU+8PUt4ZpjCVmhWwiIQsr4McOB4hGXD0/lpyVkYXyZaC86eBNJepJIRhLzLIVQStK0IrSFrHbGa2JYWIkJGUZHh+GIZimgWka8cQs24qiosS1/Li2H9P0bUfXjxmtmYbgSdDw2+n6Ipiu2N3diVkSv27yiVl70vM7O+ZA0YlZ3YwYmB5fUq03op/0NRqNJhE5vJ/09aCv0Wg0CQh6nr5Go9F8rjicB/1eoelnN1RSmurh0eFfBWDZNQ+wbs4rzP7VOTx85aNcfWI5D1sT2Dx/Bt++8xKqbr+SxQ1Brrj3LLL7DefpGybxyc3fZWlTkAtPGUjrOXfwu2eX4q/exMBjp/Gj04ay/c+/pWDoBL55/ijKKz9g6ZPvs7olRP80L0d+YRS+067m1TU1rPxkO83b1pK27j02/PcDlm1poj5sk+8zGVmaQf+TR+MbP431zYp31tVSWdFA3zHFlE4ejWf0sVSGTD7e3szSTfXUV/sJNOyIz9H3pGWSklNI4/pqmrc1syMYm6O/y2gt0+Po+TmpHjJK0mmtbqWlKURTJEowqgjYu4zZYuf4DCHVkPgc/VDAIhSIEAlZRIJB7LAzR9925+nHtHRJy0L50lDeFKLeNEJWNK7nh21FW8SmLRIlZEfjRmsx47W4nu/O2TdMA8NjIIYQtZyCKUopp2BKB6O1mOFbrHVptObO0TcMiev5Xc3Rj7EnPb8jyc6t70r3j13nUNXzP2sOia7refoajUbzeULLOxqNRvO5QUQwvL1zZk4y6EFfo9FoEtGGaxqNRvP5Qg/6nzE7qv1ct+NDsi/4Lf5Fj1N4+5+ZdsP1tN56Ga12lAmvv865F/2aISdfxN19qvjB00v44sgCgl/9BZcPqqB87mP89K2NHJOXyvgHf8K1M1azaf4scspHccsXj6Rs9f8x/YkFjPvp9Vx1ZCEbbr+D9ysaMEU4bkQ+A666lCWBLJ599xNq1nxE1Aqzc8YrVMzdwtZABJ8hDM/0UT61H3knnExj7hDeX1XDh2tqaKisos/EgWSMm0IgfzArNjUxf10ttZUttNZsIdTS4CRCeXz40rNJLyij8aMmqlvCNER2BXFNgUyPQbYbyM0oySCzJIP6dQ3Uh50ErsTqWtA+iJtmGtS3hmhpDRMKRggHLCIha5fRmpuYFU0IoCqfY7KmvOlYGITtqNucIG7IjhKybKdyVoLBmtkhiGt6DEyP4QRKPUY8Ecu2VNx4LZaYlWi01i6Q2yExq12ClpuYFauctbcgbiwxCzoP2MZITMza3yBudxutHQx6QRcPCkZv+J+1n/SK2TsajUZzsBARxEiuJXm9s0RkjYisF5G7O9n/kIgscdtaEWlM2Gcn7JveHe+vVzzpazQazcHENLvneVhETOAR4HRgG7BYRKYrpVbFjlFK3ZFw/K3A+IRLBJRS47qlMy76SV+j0WgSEbrzSX8SsF4pVaGUCgPPARfu5fgrgGe74V3skV4x6JcUpDH+NyspO/pUTp0lmClpvH4aPPLcKr7zyBWc9Nv5WMFWXv3+yfzvzG/hM4RTXvw1lz22kAdPKWbmLc8QjirO+e6pvCUjePOVeQCMPX0K143MYNn9TzC3to2fnTsa+78Pseg/q9kRtJiQm8qY646nbex5PLFgMxs/WUNbXRVpeaWsn7GUpU0hAraib6qHYaMK6X/aRBg5lU92tPLGyh1Ub2nEX72JoinjiQ4az4aGEIs2N7BhUyNN1bUEG6qxgn4AfBk5pOWVkpWfSeN2PzuCVjuNPs004kZrOfmpZBank1GaS1PQoikSpdWO7ma0lmi2lukR6mJGawGLcMgiEmzDDgewQ4F4QlQ0sisxKupNR/nSiXpTCcWSsqKKsB0l5BqtxV5jGr5htE/OMj0eTNNJynKSs5wCKlHb1fLdBK1YYlaing+OTm6K7LFwSiypynATtPZGop4Pe07Miun5iexr0tDe/mElXutA/gEebkZrh0RiFjGXzW4b9MuArQnr29xtu99XZAAwCJidsDlVRD4UkQUictF+vqV2aHlHo9Fo2tH1A0QChSLyYcL640qpx/fzxpcDLymlEp9OBiilKkVkMDBbRJYrpTbs5/UBPehrNBpNe1x5J0lqlVIT97K/EuifsN7P3dYZlwM3J25QSlW6rxUi8g6O3n9Ag36vkHc0Go3mYNKN8s5iYJiIDBIRH87AvtssHBEZCeQBHyRsyxORFHe5EJgKrOp47r7SKwb9QMkA1r/7GssfPIf5f3+G6X+8gScnX88XRxbw+sRv8skrz3LFLVeR8cidzNjWzFdvOY7H/UNY8t//sP62G3hrZytfOLoPObf/jrv//hH1FUspn3Q6D3/xKBqf+BlvvbsFgPHhtXz0+5ksbghSmuph4lmDyf3i1/jPp7W898EWGjatwPD4yB86gZVr6tkRtMjxGozJT2PAqSNJn3IOmyMZvL22hg3r62jcupZgUw2+o05kB9ks3NbEB+tqqdvhzNGPG62lOkZrGYWl5BalUxmwaLaiuxVDz/eZFKZ4yCjOILNvFpllRdSHbVrt6G5Ga6Y4Wn6qYZDpcVpba5hwIOKarYWxAv7diqHH9HzANVtL21U0pZ3R2q4WiNi7jNU8Pqd53VdXzzdNI15IJT5P325vvJZospbYErV8Xwdt30iYo29K8kZrKmp3abR2IHP0d11jz3P0u1vP780cKno+OH0xPZJU6wqllAXcAswCVgMvKKVWish9InJBwqGXA88ppVTCtlHAhyKyFJgD/Cpx1s/+ouUdjUaj6UB3OpUqpWYCMztsu7fD+k86OW8+MKbbOuKiB32NRqNJQNzZYIcretDXaDSaDuxDILfXoQd9jUaj6cDhPOj3ikDups07+MEv7+CdkZOZctXVFPzyBja1RThpwSxu+dE/KJ9yHo9NtPjLA7O5cEAOafc8xs8eeh1fRg7PvrCKsTmpHPfYvdw+41PWzH6d7H7Duenyoxi+ZTYLfvc2m9oiTC1Io+Kh3/LOsp0AnDgsn2E3fJlV0pen3t7AjpUfYYcDZPcbzpCjSlnrD2EKDM/0MWjaAIpPO5Xm4tG8u6me91ZUU7NxG221VaioTaB4BMuqW3l/XQ07tzXTvH0TwaZaolYYw+MjJSuP9IIycoszGNgni1rXQM1WToJVmilkewyKUkwyStLJ6ptJZlkRGWVFNEU6C+I656S6AeBMj5CZ4iHYFiHkGq3Fgrh2KIAdDmJ3qFYFoLzpRMRDyIoSdKtmBSNR2iK7ErOCdpRA2HYTsXY3WosFb02PgWE6CVq2pZwA7h6M1oB2/ejMaC1eTUuIJ2bFfpJ3FlRNTMzaW3WrRKO1jtv2xL4EcXsyYHmwKmbtwxz23ok47zGZ1hvRT/oajUaTgOA8nByu6EFfo9FoEpHD21pZD/oajUbTgd5cXL4resVvGG96Fjetfpw3tjUz+2x46ImPufuxK5n6+48JNdXy+k9OZ+bx12GKcMbMh7nojx9Qu3YxJ15+Pn4rysU/OJ0308Yz/fl3UVGbo88+gW8ekcnSn/6Rt3a20j/Ny+TrjuH9Z5dT5Rqtjb3xJAITv8DDcyuo+PhTWmu2kpZXSv8jR/OVKQMI2Ir+aV5GjSlmwNmTYcwpfLi9ldeWbWf7xnr81Zuwgn4Mj4/1DSHmVdSxtqKBhsodnRqtZRfmUFSSyVH9c3czWsv2mHGjtaw+mWSU5pJZVoSnqMxNzGpvtBYrnhIzWsvxmqRkpxAOWE5iVoLRmh0O7ma0FiNmtBZMMFqLJWTFjNYCYafF9fwORmuGx4gbrcUKqezJaC2xD3HTtw7JWfEkLdOI6/hew3C0/Q7/UGOJWXvS87syWjOkezX4Q9Vo7bPmUOu6Y7iWXOuN9Hi3RcQUkU9E5DV3fZCILHQLCjzvpiZrNBrNoUFsckASrTdyML6rbsNJP47xAPCQUmoo0ABcfxD6oNFoNEkiGKaRVOuN9GivRaQfcC7wpLsuwCnAS+4hzwDd4hGt0Wg03YHoJ/0D4vfAXUDUXS8AGl0TIth7QYEb3eIBH5akBPnx7S/z40ev4MFJN3LlsWX8feR1LH31OW77/vXIfdfz2vYWvn7vmfxqe1+W/PclBp94IS9cPZ7Lpw3E880H+O6Ti6mvWMrgqWfxyCVHUfPwPcycsxlT4LSp/eh/07dZ3BCgf5qXY78wguxLbuLZFTt5f95mGjatwPSlUTRyImccW87ZQ/PJ95mMK81k0FljSD3ufNYHU5m5qpoNa+to3PIpwaYaxDBJyyvhg62NLFhXS21Vs1sMvR5wjNZS80rIKu5DfkkGR5blMKIoczejtaIUk6J0LxnFGWT1yyGrvISU0lI8peW7zdGPafkZpmOyluM18aV7Scn2EQpECAcCWAE/kaDfNVoL72a0FsOZn++YrIUsRUtod6M1f9CiLWzv1WjN9LivrsafrNFarEh7MkZrhtHecG1PRmuJdGW0Ftvccd5+IgdqtNYdWvzB1PO7e276oabnx+jOGrmHGj026IvIecBOpdRH+3O+UupxpdREpdTEwoKCbu6dRqPRdI4InScDdtJ6Iz05ZXMqcIGInAOkAtnAw0CuiHjcp/29FRTQaDSaz4TeOqAnQ4896Sulvq+U6qeUGojjFT1bKXUlji/0l9zDrgH+21N90Gg0mn1FSO4pv7d+MXwWyVnfA54TkZ8DnwB//Qz6oNFoNJ0iAj5tw3BgKKXeAd5xlyuASftyfu2KNVwyYTyPDLkWHy8x7H9vcM75P2bMeZdyT9rH3P3YYq48toz6a+/nwev/SGbpQJ6643gqv3M1E5/8Pef/awnr332NgqET+PG1R9Nv8T958Y9zqQpanN8vm3Hfv475dj98hnDyhFKG3vwN5vmzeGrWx2xf/gF2OEDh8GMYO7GMqyb0o7B6CUdmpzDkjCEUnXEONblDeXNFNfOX76B240ba6hyjtZSsfDJLBvHWqmp2bG6keXsFwaZaJzjpSyM1p5CMonLySjIZ0T+XMWU5DM1PZ6ZrtJbpMcjzmhSlmGT1zSS7n1MtK6NvMZ6Scsgp3i2I6zN2Ga3leA3SfCapeamk5aUSCkR2VcuKhB2jtYgTzO0skOtUyooSsnavltWakJgViNjtgrimxzFYixmtiUg8Scs0jd2M1qJWGGW3D+LCLtO1dklZHiMevPUmJGglGmAlBnH3x2gt8QFuf4zW4ud2YrTW3UHcZO/fPdf7nARxxTH5O1zRNgwajUaTgHB4a/p60NdoNJpEpPfq9clw+ApXGo1Gsx84T/pGUi2p64mcJSJrXOuZuzvZf62I1IjIErd9LWHfNSKyzm3XdMf76xVP+raCAf97g7PPvRv/oscZcudrZBT1Z/73pvBY30mMykph8uuvMOae2bTVVXHXfbcy7qO/8eu/fkz2ZZnMf+lFfBk5XPrlk/hi9k7evftvzKsLMDYnlWO/dyY14y7m3r9/zJ3FmYy/40K29p/KAy8tZ+OHHxNsqiGrzxAGTxjJ144byHCjjtrpLzDi2DL6n38q1uhTmLuugekfVbK9Yif+6k3Y4QCe1EwySwZSWF5CxYZ6mqoqaaurwg4HEMPEl5FDRlE5uUUZlPXN4qj+OYwszKA0w/lfkqjn5xRnkN0vi+zyYrLKSzBLyjGKy7GzSnYzWktzk7IyPQbZXpM0V89PzUvFCvixwwH3tfPCKYmELOUYrlnRBD0/SshyCqfEErNiRVQMj29X0ZSY2ZopcX3fMATTI9hWlKgdxbaseOGUzhKzYrQzXBPBa+zS8WNGa6bs/pN8b3q+Eytob7S2p8IpHXX+feWzKJxyqOv5hzrd9aQvIibwCHA6TjLqYhGZrpRa1eHQ55VSt3Q4Nx/4MTARUMBH7rkNB9In/aSv0Wg0CRiyKwO8q5YEk4D1SqkKpVQYeA64MMmunAm8qZSqdwf6N4Gz9utNJaAHfY1Go+mAM0Os6wYUxuxi3HZjh0uVAVsT1vdkPfNFEVkmIi+JSP99PHef6BXyjkaj0RwspBOpcC/UKqUmHuAtZwDPKqVCIvJ1HCPKUw7wmnukVzzplx4xmClff4qyo0/l1FlC9fK5zHjoauYddzpVwQjXvnYfZz79KRvfn87kyy/lx8P8vHDjX2mK2Pzu0bcJNFQz/vyzeeDMway46/vMXF1LaaqH0686isxrf8QvZm9g9XufcPStJ8I5t/D79zax7L3VNG9bS2pOEf2OGs9XTh7MtPJMwrP/xbpXP2bYxVMwJp3P4u1tvLqkki1ramnasopQSz2Gx0d6YV9y+5UzeEg+dZW1+Ks3EWltApzCKekFfckpKaS4LJsJA/IYXZRJv2wfmaF6txC6o+cX5KWS2TeTrH55ZJWX4CsbgLfvQKKZhYR8WUCini9kmM78/ByvQUqOj1RXz0/Ny8AK+okEdhmtdVY4JYYYJkHbKYjuD1v43fn4bREbf8japedHbAJhC8Prw/R4HMvZ2Jx8j7Sbr2+YjmVtYuGUvRmtxfT+uOFawrz8jkZrsXn6nRVO2RPJFE7ZV6O1xOt0PP9gGa31hoknh3qIoBszciuB/gnru1nPKKXqlFIhd/VJ4Ohkz90fesWgr9FoNAeLWHJWMi0JFgPD3OJRPhxLmunt7yd9ElYvYFf9kVnAGSKSJyJ5wBnutgNCyzsajUaTgCDdZsOglLJE5BacwdoEnlJKrRSR+4APlVLTgW+JyAWABdQD17rn1ovIz3C+OADuU0rVH2if9KCv0Wg0Ceyjpt8lSqmZwMwO2+5NWP4+8P09nPsU8FS3dQY96Gs0Gk07Dncbhl6h6a+qiRBqqWf5g+cw/+/PcNd9t5J7/w28sHwn3/75ufyqbSwf/OvfDD7xQv73jUm8c9FNLKgPcMVpg6j5dAHDpl3I3645mtoHbue/M9ZhK8U5J5Uz6Hv38MTyembOXEl9xVIKr/8uTy3Zzsy31lO7djGmL43i0ZM5/6RBfGFkITL/BdY+P5dlK2rIOOWLrLeyeWlpFctX7KR+4yoCDdXxalm5/YfTd1Ae00YV01K1vl21rLSCvmSX9qOgTyYTBuQxpk82g3JTyTdCeOo3k+MmZRWle8nul0VOeS7ZA/uQ2r8/3r4DsbNLsTOLaBIaYMMAACAASURBVAg6wcTOqmWlZ6eQmusmZuWmkZKbRSToJGfFjNb2FsQVw+y0WlZrePcgbrxylplotLaHJC2P0a5aVmIwubMgbqLhWmK1rFiClje23Q3odkZniVm7vee9VMsyhHa2a10FcROvGWNPQdz9HVt0taweRBdR0Wg0ms8PMT/9wxU96Gs0Gk0H9KCv0Wg0nxOMw7yISq94Z8HmRt548nbeGTmZKVddzV31L/H7v3zINy4ewfIv3Mvv7n+G/MFj+e8Pp7Huq1/kheU7uWhwHhOe+jOlY6fx+69PpuTNh5nx8HtUBS3OGZbP+J/dzuv+Yv784gqql8/Fm5HD67WpPDljNVVL56KiNoXDj+H44wdyzdH9yN80j00vzGDF+1tZ6w9RmTWE6aurmbekiup1a2it2RovnJLdbwSlA/I45YgSpvTLI9BQHS+ckpZXQlbJAArLshkzMJ+x/XIYUZhOn3QDT90mwhUrKfSZlKZ6HD2/XzbZg/qQUV6Gt89AVF5folnFNISiNAbteOGUXXq+QUaap53RWlpBDqkF2dihAFErstfCKTE9XwwzruO3hHcVTvEHLcdsLWThD0bihmsxvd7jNXcZrCUUTolr/YbssXBKRz0/hs9j4DWMPRZOMY32RVS6MlqLv9e9FE5J1PP3dH6y6MIpuzjk9XzQmr5Go9F8nhDivjqHJXrQ12g0mg4czlbSetDXaDSaBAT2OP33cKBXDPr9+pdi3Hwpb2xrZvbZ8INxT3HB0Hzyn3iZs274K2IYPHLPRWQ8ciePvbiaY/PTOO2l+/nJ0ig//OaJnLhzDv93x7MsbQpyWnEGxz9wDSv7nshPn1zEpkWzEcOk/JhpPDB9FZsWzSfS2kT+4LGMnjKMW08YzODWdVQ+9yxrZqxlRXOIgK14fV0dMxZuZfvazfh3bCJqhfFm5JBdNpzSgUUcN7qY4wfmM6IghagVxvD4SM0pJLN0EPl9shhWnsuEAbkcUZxJWaYXb916rI0raF2/ztHzy7LIHZhD9qBSsgf2wdN3EFLYDyurhCbLoCFos70lFDdZi+n5OameuMlaemE6qa6en1qQ48zR30vhlEQ9XwwTf9jGH7Z2Ga0FnTn6LSErPj8/ELaxIraj5Scaq8U0/IQ5+x7Xgzym50e7KOISL4yeYK5miOA1pV3hlMTlZPV82F3P78x8DZxBwBDZJz2/swfFjnp+d8/RP9T1/F6D+1k7XOkVg75Go9EcLATwJlkKsTeiB32NRqNJQMs7Go1G83nCnRJ8uKIHfY1Go0kgFsM5XOkVwlVu03aeeG0dP370Ch6cdCOjslI4+eM5TPvBLJqrNvDDe67l9KVP8JcHZtM31ctlf/smf7dH85fHXuOGwmre/doDzKpuZUJuKqf97EJ2Tv0qtz23hLXvvoMV8FM6dhpXnTeST+d+QFtdFVl9hjDs2KP49qnDGOupofbFv7HqhSUsbgjQFIlSlGLy3Aeb2fppJY1bV2MF/XhSM8nuM4SSwWVMGF3MtGGFHFmcTtrONYhhOkHckkEUluUzeEAukwfnM7Ykm/5ZXlIbt2BvWU1g/ac0rttKfkkGuQOyyRlYQs6QMrz9hmKWDsLO6UOrpNIQsqlqCVHZEiQtIYib53OSstIL00kvSCO1ICsexPXk5mO71bJiAdTOiAVxTa+PlpBTMavFNVmLG62F7fhrOGxjW9HdjdViCVkep1qWJ6GYdMekrD0ZrcXaLnM1I14lKzFRa1flrF3vI1mTtcTlWBC3XXD3wD66e/wH1v1B1+6+XvcPer1pHHWM/bpuvRH9pK/RaDQJiPtAcbiiB32NRqNJ4HCXd/Sgr9FoNB3ordJNMvSK3zDbd7TwvTtP4JEh1wJw1dKXmPTzeWxb/D+uuuOrfMuez59u/AemCDc8+CXeGX4Z9z70Jk1bVvPBNXfy6po6hmf6OP+uU7Gv+BG3vLyc5W/OJdCwg+LRU7ng7BHcPLkfLds3kFHUn6HHTuL2s0Ywrcii5dW/svKfC1lU1UJNyCbHazAhN5WNK7bTuGkFkdYmTF8amaUDKR4ymDGjijljZDHj+2SS07SR8Ip5pOYUkVkyiIL+xfQfkMtxwwoZ3yebgbk+MlqrUVtXE1y7goa1W2lYV0Pe4FxyBhWTM7QMX7/BePoOxs4ppc2TSV3AZkdLmO0tIbY1BMj2GOT7TPJ9pmOuVphGemEaaYVZpBbkkF6chzcvDyO7YK96fmJSlun1xZOz2iVlBS38IYuWYCSu51sRGysSxfAYeLztTdc8XiNeWCWm56d4jF2Ga13o+TES9XyPaSRo+Lv0fK+5yy8lGT0/fm3pWs83RPZLj+7uwil7vE8vGKB604OzsMvAr6uW1PVEzhKRNSKyXkTu7mT/t0VklYgsE5G3RWRAwj5bRJa4bXrHc/cH/aSv0Wg0iXRjjVwRMYFHgNOBbcBiEZmulFqVcNgnwESlVJuIfBP4NXCZuy+glBrXLZ1x6RVP+hqNRnOwcDT95FoSTALWK6UqlFJh4DngwsQDlFJzlFJt7uoCoF83vp3d0IO+RqPRJBCzYUimAYUi8mFCu7HD5cqArQnr29xte+J64PWE9VT3ugtE5KLueH+9Qt4pzkvl/S/fz8+/eT/+RY9z/N93sHrWS5z5zRt4dMROnjjplzREbG7/6dmsO+u7fPO+N9i5ah5DTr6I5/9wG31TvVx80xRybv8dX395BR/MeBd/9SYKhx/DGeeO5funDCZl9pOk5ZUyePIUbjp3JOcNSCX48u9Z/vRcPljfQFXQItPj6PnDTh1IQ8VSgk01GB6fq+cPZ+TIQs46ooRj+mZR2FaFtWIetQs+JqNoInllpfQtz2XqsEIm9MlhcG4K2cFaZNsqguuXUf/pZurX7KBhYyNDzhpB3vD+pA4Ygrd8OFZOXwIpedS2Wezwh6lsDrKloY3NdW0c53Xm6KfnO1p+emE6aQWZpBXlOXp+bi5GbjFmXlGXhdANjw8xY8te/GHLLZayS88PhJ0iKoGgFdfzrYjtmKolzM83TInr+Wk+M67n+zxmUvPzIWa4Fu1Uz/cmLDtF0WWfTNFU1G5XCB32rOfvD8nq+QecB9ADWvnhPHMlKQT2YcZmrVJqYrfcVuQqYCJwUsLmAUqpShEZDMwWkeVKqQ0Hcp8ee9IXkVQRWSQiS0VkpYj81N0+SEQWukGN50XE11N90Gg0mn0lNmWzmwK5lUD/hPV+7rb29xQ5DfghcIFSKhTbrpSqdF8rgHeA8fv9xlx6Ut4JAacopcYC44CzRORY4AHgIaXUUKAB5+eMRqPRHCKIa+fddUuCxcAw92HXB1wOtJuFIyLjgb/gDPg7E7bniUiKu1wITAUSA8D7RY8N+srB76563aaAU4CX3O3PAN2iU2k0Gk130J1P+kopC7gFmAWsBl5QSq0UkftE5AL3sN8AmcCLHaZmjgI+FJGlwBzgVx1m/ewXParpu9OVPgKG4kxb2gA0un8I2EtQww2I3AjQJz21J7up0Wg0cRwbhu6LayilZgIzO2y7N2H5tD2cNx8Y020dcenR2TtKKdudY9oPZ+rSyH0493Gl1ESl1MSMQcP5xrd+R9nRp3LqLOGjF//F1Guu5b+nmvzzlNtY6w9x850nUX/t/VzxqzlUfTSLAcedz+O3TiXfZ3LZV8fT554/cOf/rWHWy3Np3raW/MFjOfncifz4jGHkfvAvPv71iww69nhuPG8Ul4/Mxfq/R1n+1znMX1HD1kCETI/B2JwURp48gMEXTyPQsCMhiDuSEaOLuHBsX47rn0NJuBpr+VxqP1hM1cIK8vv3p+9AJ4h7dFkOQ/NTyY00INtWEVr7CfUrNtKwZjsNFY3U1AbIG15O6kAniGvn9CWUXkBdwGJna5itTQG2NAbYXNfGtvo28n0mmXmppBemkVGSQUZxFmlFeaQV5OAryMfMK8bMKcDIyidqhXf7O3cM4poeH4bHi+Hx4Q9ZNLVF2gVxW4IWoYSkLCtiE7Wi8cpZHp+JYUo8QSsxKcvnMXdVzkoyiAvEq2btKYjrjVXP6uTTvKeKXLAriBuroBX/m7ivsSe5A4lrfpZB3P25/uc+iOsiklzrjRyU2TtKqUYRmQNMAXJFxOM+7Xca1NBoNJrPEuOAv5IPXXpy9k6RiOS6y2k4GWmrcbSpL7mHXQP8t6f6oNFoNPuKoJ/095c+wDOurm/gBDBeE5FVwHMi8nOc9OO/9mAfNBqNZp/pDX5G+0uPDfpKqWV0MqfUnW86aV+uVbFpB+VfnsryB88hZ8pNTLnqat66KJt/TbyCpU1BvnX78bTd/jAX/3w2Wz54jfIp5/GXO45n4qrnKL12HP3vf5w7Z23mlWffoXHTCnIHHslJ50/h/nNHUfzh83x8/z95+6PtfP23o7lmTCH2jD+w5JFZzF9Szaa2CGmmMDYnhTEnlTPskml4T/gShudXZJYOpGjoaIaNLuKicWVMLc+lT6SG6Iq51M5bQNXCDVSvqKH0wlxOHFHElAF5jCpMp8BqwKhcRXjtJ9Qt20Dd6krq1jWwc2crO4IWaUOG4Rs4EjuvP6GMonhS1pamIFsaA1TUtLK5tpXmxiCZealkFGc4mr6r56cX55FSXOjo+XnFGDmFRNNydvu77k3PN7y+dnq+PxiJ6/nhkIUViRK1nGZFoqSmezvV89N8Zjs932ca+6Tnq6jtGq5Jl3p+Rz16b3p+jEQ935A96/n785NY6/m9lF78FJ8MSX2WReRiEVknIk0i0iwiLSLS3NOd02g0moONdO88/UOOZJ/0fw2cr5Ra3ZOd0Wg0mkMBLe9AtR7wNRrN54XDeMxPetD/UESeB17FsVcAQCn1nx7plUaj0XxG6HKJDtlAG3BGwjYFHJRB35OWyeqHz2XOyMlMufVh5nwhk78f7QRxb7vzRNru+CMX3vc2m+fPoHzKefz1zhOZtPLfTP/aY1y0YT63u0Hc+oql5A8ey0nnT+E3F4x2gri/eIa3FlVRFbS466giojP+wCd/nMl7n+yIB3En5KZy1CkDGXbZqXhPvJRPrZx4EHf0mBIuGlfGiQNy6WvVEF3+DjXvzady/nqqV9SwpiXMtFHFuwVxQ6sWdRrErQ3b8SBuMKOIGjeIu6khsFsQt605REZxRrukrD0FcTsGcvcWxDVT0jA9vi6DuLEELduKJh3E9XmMfQriAkkHcRM1Vh3E1RwIh/GYn9ygr5S6rqc7otFoNIcKh3OhkWRn7/QTkVdEZKfbXhaRHq3uotFoNJ8F4pZLTKb1RpL9Qvsbjh1oX7fNcLdpNBrNYYfOyIUipVTiIP+0iNzeEx3qjCP7ZfH6oInMrW1j9tnw5NFXsdYf5jv3nEHN1x7gC/e+QeXimQw+8UL+ceeJHPHBY7x089+ZVxfg9RkV/N/zb9O0ZTUFQydw5heO4xdnjyB/3tMs/sW/eXtJNTuCFgPTvURe+g2fPPIG7y3fZbI2ITeVMacNZOhlp2OeeBmrgxm8sLSKkmFHcORRJXxhfBnH98+hNLQda+kcat5fyLb569mxqpb1/gjVIYvzB+YzojCNgnCdUylr1SJql22gblUV9evrqakNUBmwaIjY+K0oVv4AQukF1LRZVDY7Jmsb651KWYl6fltLqJ2en9GnYJfJWkEpkl1INDXL0fRTsuJ/z2T0/JjhWmd6fsxkLabn23Y0aT0/xWPsk57vVLhKTs+PafHJ6Pmw90pZHfV82c9/4V3p+d39sNhLx6FDCkHLOwB1InKViJhuuwqo68mOaTQazWeFiCTVeiPJDvpfBS4FdgDbcQzTdHBXo9Ecfri/AJNpvZFkZ+9sBi7o8kCNRqPp5QhODYfDlb0O+iJyl1Lq1yLyR5x5+e1QSn2rx3qWQP3yNSww+vDjR6/gwUk30mzZfP+hL/LJmXdx3d2vUr1iLqPO/BLP33E8pf/9Ff/83n/4uDHItKJ0vvn31/BXb6J49FQuuvgY7jtjKKn/+xMLfvkys1fXUhOyGZLh48QpZSz+7UzeX1dPVdAix2twTF4aR5wzhEGXnYcx5WKWNpk8+8lW3ltSxYQJfbjILZpS1LqFyCezqX5vEVULNlL1aR3r/WGqQxYBWzG6KJ3cQDVsWU5g9cdxPb9ufQM76wPsCNpxPT8cVbSl5lPbalHZHGJLU5CNda1xPd/fGKS1OUTAHyLU0kxmn5wEPb8AI7cYM6/I0fPTclBpOdgpmbRFHK08Uc83vT532YvpS8Pw+jA9PmfZ46OxLUwgbBMIWu2Kplhhm6itsN25+nasiIqr5ScWTUnzmfjM2LrT9kXPB9rp+V5zl37fUc83jeT1fOhcz+8uLT/x+jG0nt976K3STTJ0Je/ErBc+xCl72LFpNBrNYYWTkdt98o6InCUia0RkvYjc3cn+FBF53t2/UEQGJuz7vrt9jYic2R3vb69P+kqpGe5im1LqxQ4dvaQ7OqDRaDSHGt31nO/WE3kEp4jUNmCxiEzvUOD8eqBBKTVURC4HHgAuE5HRwOXAEThT5d8SkeFKqc5/uiZJsoHc7ye5TaPRaHo5jlyYTEuCScB6pVSFUioMPAdc2OGYC4Fn3OWXgFPF0ZcuBJ5TSoWUUhuB9exjLZLO6ErTPxs4BygTkT8k7MoGrAO9uUaj0Rxy7FviVaGIfJiw/rhS6vGE9TJga8L6NmByh2vEj1FKWSLSBBS42xd0OLcs6Z7tga5m71Th6PkX0F7DbwHuONCbJ0s4qvjpa3fzO+/J+HiJH7xwG8/2vYi77/oHzdvWcvQlV/LKzcdi//7bPPGbOWxoDXN+v2xOeeRrXP3T5ZQdcw7XXTKGu44vJ/iPnzH3gdd5a0sTfivKkdkpTJ02gFHf+BK/uOgBakI2RSkmk/PTGXnxKPp/6ULUpIt4v6qN5z7ezKIlVVSvq+C+yy5hUlkWuXVrCX30Ftvnfkjlgi1sq2hkvT9MbdgmHFWYAnn+rUQ3LqVt5RLqVlZQu6qahopGdjQG2RHclZRlu6Hy6jYniLupMcDmujYqavxU1QfiQdxgW5hQSzORtibSRxeQUVqAtyBmslYEmQVxkzXbm05rOEpbJLorIcswMb1OAlZipSyPG8CNJWn5gxbhsN1pENcK29i2k5wVtaP43ACuz2OQ7jPbJWUlBnF9HqNdEHdX0HZXEDcx8BqN2kkHcTt78tpTEDdGskHcfQ266iBu70WUQrr43CRQq5Sa2JP96W660vSXAktF5F9KKf1kr9FoPheIinbXpSqB/gnr/dxtnR2zTUQ8QA5O8msy5+4ze9X0ReQFd/ETEVmW0JaLyLIDvblGo9EceihQ0eRa1ywGhonIIBHx4QRmp3c4Zjpwjbv8JWC2Ukq52y93Z/cMAoYBiw703XUl79zmvp53oDfSaDSaXoPaLS1pPy+jLBG5BZgFmMBTSqmVInIf8KFSajrwV+AfIrIeqMf5YsA97gVgFU4M9eYDnbkDXcs7293FWiCglIqKyHBgJPD6gd48WfocMYgrq8Yy8y8P41/0ON9dV8hf73qMqBXmrK9fy/OXj6Li1iv497Mr8VtRvjypL1P+cBeLS05g6EnzuevKcXy5XLHz17fzwaPvM7e2DYCpBWkcc9EIhtxwLY2jzqAm9Ev6p3mZNCCbkV8cR58vXkLr8JOYXdHIcx9uZcWyanZu+BT/jk2cNCCH1K0f0brgTSrnLqFqURUbtzWzNWBRn6Dn53hN7E8X0rJiKXUrNlK3ppaGikYq/WFqQk5SVsDepef7DKGiPsCWpiCbalupqPFT3RCgtTlEW1OINn+ISGsT4bYmrICfzLIivIUlGG7RFDJyiabmEE3NJmKm0Ba2aY1EaYuoPer5iSZrZoqj63t8XkIhCyscK5Ziu8lYTgGVRD3ftqwELd/Yq57vSzRcS9DzOyZkRRM0Va9pYAhd6vkdJf1k9PyuDNYOVHvv7HSt5x/iKJXsU3ySl1MzgZkdtt2bsBwEOp0Cr5T6BfCLbusMyU/ZnAukikgZ8AbwFeDp7uyIRqPRHCqIiibVeiPJDvqilGoDLgYeVUpdgpMwoNFoNIcZCqJWcq0XkqyfvojIFOBKnOwxcPQpjUajObxQdKu8c6iR7KB/O04G7itucGEwMKfnutWe1XU2y/74F8qnnMeps4QF//4TmaUDueP2i7l7sJ/5p5/Di4uqyPeZfPWSUYz+9QP8uyaPX/1hPo/ePIUTqGDt93/JnJc+ZWlTkByvwQmFGYz96iTKrvs6FdmjeHreZkZlpTDxqGJGXDqJvPOvZHvOcP63cifPLdrKplU7qa9YQVtdFVErjG/V29TPm03l+6vY/tEO1te2URW0aIrY2MrR5nO8Bn1TvdQvXEjdik3Ur2+gbnMTlQGnAHpTxNH+E/X8TI/B2rpWKna2srmulbqGAG3NIWd+fmuQcEs9kaAfK+DHDgfxFg/BLCjFzCuOF0tRaTkE8dAWjtIaiRKworSErLihWuLcfEe/T2uv57vmaZGQHZ+P72j6Kl5AJabpq6hN1ArH9fw0n6ddwZSYjm8aspumD13r+cq22+n5Hefqwy4930hQt7vS82PnQXJ6/v74b/X03PzO7qHpDhREP+eDvlLqXeBdEckUkUylVAVwUBw2NRqN5mDTW/X6ZEi2MPoYEfkEWAmsEpGPRERr+hqN5vCk++bpH3IkK+/8Bfi2UmoOgIicDDwBHNdD/dJoNJrPBqUgeRuGXkeyg35GbMAHUEq9IyIZPdQnjUaj+Uw5nOWdZAf9ChG5B/iHu34VUNEzXdqdQFMDU+/4Cm/cOoWcKTdRPuU8Hv/2CUz59AVeOfZR3trZyticVC78zjTyvvMQ3521nhdfeovqFXM59pxaFv7yad78oJKqoEXfVA8nH1XM2BtPIf2CG5nXksHjs9awaOE2nj99IMMvPxXvSZfyqZ3Pyx9V8vribVSuraJpy2oCDTsASMnKp/q16VR+sI4dS3eypsWpkuW3nA9KmikU+jyUpXnoU5DGjoXrqFvXwM6drXGDtaaIUyULnNJssSButsdkZWUzm2tbaW4M0tYcoq0lRKjVT6S1qV0Q1woF8JSUY+QUxg3WoilZtFmKtohNqxUlEInSFLRoClm7BXHjAVy3apbHl4JhGnh8Jh6viZVgtma7wdt2iVlW2AnkRsJOANdNyOoYxI0308AQ2WuVrFgQV9kJyVmGsdeErFgAVyS5AG7i/boK4u5vAaVkgrgHUp1JB3B7ku5NzjrU2JfC6EXAf4CXgUJ3m0aj0Rx+fF41fRFJBb4BDAWWA3cqpSIHo2MajUbzmdDNNgyHGl3JO88AEeA94GxgFM6cfY1GozksET7fmv5opdQYABH5K91g67k/9O1XypwzIrw5cjLH3fYHXr3hGBp+8nUefHQBVcEIXxiWz0l/upmKoy7hy39eyLJZ7+Kv3kRO+Sjeuu4h5uzwE7CjTMhNZcpZgxl+w+WEj72Ef6+u5al3lrPh4w00bF7B6N/ciD3+XGZvbuaFTzbw4ZLtVK9bR3PVBqygH8PjIzWnkOx+I1g341G2bmpkY2ukXcGUTI9BSYqj5xeXZZE/LJ+qRVVUNYfYEbRpttoXTDEF0kyDTI9Bntck32cws6oZf1OQQEuYgD9EqKUxbrBmh4NY4QDRSJioFUby+2CnuQZrnjTawlEClqI1EqU1bNMUsmgKRvCHbUxf6u56foLBmmkaeLwmhsfA4zUIh6w9GqzFtPxYclaaz9yjwZppCD7TwGsIhiF7LZgC7fV8FbW71PPjunySQneinr+3gimJknuyOmhnHG56/gF0vZegwD58Z+909VmOSzn7WkRFRPqLyBwRWSUiK0XkNnd7voi8KSLr3Ne8/ei3RqPR9AwxG4bDVNPvatAfKyLNbmsBjooti0hzF+daODGA0cCxwM1udfe7gbeVUsOAt911jUajOWQ4nF02u/LT329TNdeLf7u73CIiq3GK+l4InOwe9gzwDvC9/b2PRqPRdC+f70ButyAiA4HxwEKgJKE4yw6gZA/n3AjcCFCWk8kDU26mNmzx9pmKd487mZdX7KQkxcOtXx3HkJ//jqc2e3jwF7PZsuhNAMqnnMcl545kxnmPkO8zOa08j6OuO5aSq77OurTBPP7mBt6ct5mqFUvwV29CRW22Dz+TmUt28MKCLWz5tIb6imW01VWhojae1EwyivuTXz6M0oG5rHilnq2BSFyf9xlCvs+kJMVDeZaPvMG5FIwoJG94f96bVRE3WAvYuyry7Jqbb5Dj6vk5WSk01rQS8IfjBmvhtibsUAAr2IrtavkxPdzOKkKlZBFQJoEEg7XGgIU/7MzP94csmkNWgn7fucGax2vi8Rlxbb+1ObTb3PyYhh/T8+OavtfcTc+Pmax5DQNTnGIoXkO6NFiLL7vbvYaxW/HzRD3fkOR05o5z+JMxWDuUtPx9v3/33uvw1/ITOIwH/QP5TCeFiGTizO2/XSnVThJy60B2WpdMKfW4UmqiUmpiQUZaT3dTo9FoHGI2DMm0XkiPDvoi4sUZ8P+llPqPu7laRPq4+/sAO3uyDxqNRrNvKJQVSaodCMlMahGRcSLygTsZZpmIXJaw72kR2SgiS9w2Lpn79tigL87v2L8Cq5VSDybsSqz8fg3w357qg0aj0ewzioP1pJ/MpJY24Gql1BHAWcDvRSQ3Yf93lVLj3LYkmZv2pKY/FaeW7nIRiXXmB8CvgBdE5HpgM3BpD/ZBo9Fo9gmFahdb6kG6nNSilFqbsFwlIjtxLHEa9/emPTboK6XeZ895JKfuy7Wqqpooys3n5t9fwoOTbmRDa5jz+2Vzyh+vo3Lq1zj7+aUsmfU+zdvWktVnCKOnHcePLjiCU7ObeCw7hanTBjDqG19CnXw1L66p4y+vLmHDks3Urf+YSGsTntRMcvoN51dzNrDgkyp2rN1A8/YNRFqbEMMkvaAvWX2GUjywlKFD8jl5ZDGr/eF4QlaO14gbrJX2LrxafAAAH7lJREFUySR/WB75w/uSN2oAKYNGsjUwY48JWdkeg3yfSWGKh/TCNDJKMmhpCBBqaSbS1kS4tWm3hKzEgKSVlk9rJEpbvEKWTUvYoilo4Q/bNIUi+IMWTW0RvKmZTnKWG8TtLCErFtA1PYZbLWvPCVnxQG7UjlfO2lNCViyY6zGNpBKyEukqIatj1azO6MyIbV8SsvY1APtZBnG7O4ALn7cgLvtSOatQRD5MWH9cKfV4kucmNaklhohMAnzAhoTNvxCRe3F/KSilQl3d9KDM3tFoNJrewz756dcqpSbuaaeIvAWUdrLrh+3uqJQSkU4ntbjX+f/2zjw8jrvM85+3qrullmTrlixbjuX4NgkJORxCBiYkgQSWHJsNIYFhmF0yHpb7AYYkZGFgnp1nAzObsCwsYG52MjAQyEOAgElCjuUIwUnsxI7t2PER35Zlqa2jpe7q+u0f9etWtdwttXxIavf7eZ56uupX1VX1s1tvV3/fq4OgyvF7jMmFFt1J8GURA9YQ/Er4x4luWI2+oihKGGNO2kk7eipzVbF9InJIRDqMMQfGC2oRkdnAL4G7jDFPhc6d/ZUwIiLfAT5Ryj2d9pBNRVGU8sLkpMuJlpNkwqAWEYkBDwDfN8bcP2ZfNgpSgBuAjaVctCye9FsbqvnPm3/JFzZliHE/n/zo6+j8zD3cs76fb3z6N+x75mGcSIyz33A9775uBR+4pJPqJ7/H+i/fzzs++1Yab17NizKXr/5iK0/+4RUOvPgcg917AKhr76J50bmc/ao2fvXrLfTteoFk7yGMnyFaW8+s9i4aOrvoWNjIZctauWxhE69qq2WDb4i7QmPUZU51hPn1VTQtaaJpcTONKxZQt3gx0a4V+M0LSKRH9cG4K8TdUS2/KeYyq76KurZaalri1HXMZqjnUF6BtbEJWWF6hzM5PT/bLGXAavqDqUDL7xtKMzDi4cbieQlZkZgbaPqhhKywtp/T9EPNUsIJWX7owx8Pafqu1fCjblAkbVTXl5zePFFCVng76oY0/AIJWWGNfywT/WGeai2/EOOdo9QicaWiCVmngGz0zumnYFCLiFwEvM8Yc5sdewPQLCJ/Y9/3NzZS5z4RaSXwna4nKIM/IWVh9BVFUaYOMxlH7olfxZgeCgS1GGPWAbfZ9X8F/rXI+684keuq0VcURQljmKqQzWlBjb6iKEoek4reKTvKwuh7nQu54J4tbH/iIQaeXsMj7krefs+zvPTEI6QGE7Qufy2XvelcPveW5SzpeZadd/w3nvnRRp46muQT9z3Ivc8f4P4nnmb3hhdJ7H2JTCpJdX0rDV3nMH/5PK56zVzetqKdN3zv38ikkrixODXNc5nduYw5XY2cv7SF1y9q5oK5s+maHSV6aOtocbWaCM0L6mlZ1kzD0k4ali0k2rUc6ViE19BJbyb4J445QtwVat1RLb+xNkq8pYa6thpq22uJtzVSO6eJ5K8O5hqfF9PyxXERx6VveDQuP6vn948EWv7AcLA+MJymf9gjWls/Goefa4DuWB1/jL4fcfBS6eD6mfy4fONnyGS37RNRVtPPavhR2wQ96gY6ftQRXKvplxKbH94eW1xt7Bgcr42X4mQbq+ePp+WfqPZeTM9XLX8Gcwqjd2YiZWH0FUVRpg590lcURakcpi56Z1pQo68oihLCYHJ9nM9E1OgriqKE0Sf96eflXQeJPvZzOi9+M1euFZ5f+zUGDu2i/qwVXHTjdXz22pVcVnWIQ1/7e379zT/y+8ODHE1lmFMd4Z3f/jM71u/i6M4NpAcTRGvraew6h7nLz+ay8+dy7TlzuKijltmHX8T4mZwDt21BG0sXNfGXy9q4pLOeRY1VxHt34a/bwLGN6zmvvoq2ebOChCxbXC3WtRx33lIyjZ0cc2roHvTYe2yIukhQXK3RdsdqjEWoba+hpqWG2rYaatrqqe1oJt7aSLS1ndRPthcsrpZFHBcnEkMclwMDI/Tbzlj9qVEHbl8yzcBwmqFUhoFhj1QqQ6wqkpeAlUvOirq4EcFxHWKhJKvMSLJgcbWcQzcTSs6KugWLq2U7ZjkiufVSHbhZ3FBnq3BxtTzHLqPOzFIzJUtJyKo0By5UuBMXAkduOjXdd3HaKAujryiKMnVMTXLWdKFGX1EUZSwq7yiKolQIxpyKYmozlrIw+pHqWm7/7x/ljr/sov7S9zOrYxGrbnk3d12/kqsaBjj6/c/x6Dd/z+9eSdA9kqG1yuVtHbNYfuMK/vmBn+UapTQvvoA5Sxdx8XkdXHduB5d2zqLh6DZG1j7MzifX0br8GlrOamfpkmYuX97GqnkNLGqMUde/D/+55xjc8jxHnt/OkRcPsez18/MapbidgZafcOvoTnrsOzbIrr4ku3uGmFsdOa5RSlbLDxKymok2t+A2tuE2tuIl10+o5bvRoBnKgf6RoMBaMk1iKEjCGhjx6B9O57R8L53BS/vE4tHjGqVEos5xWn5VxCEei5BJJSfU8rP3WRVxxtXys4labhHdvdgfmfEzE2r5MNpgZbJ/rKVq+Scrc6uWX15o9I6iKEqlYAwmo0ZfURSlIjDG4Ke96b6N04YafUVRlDAGfdKfbs6ZP5sPb/sWj//db3jdR77EZ65dyRviRzj8nc/yyDf/wP87MMDRVKDlX9s5mxU3nUPnTTfgX3At5orbaVl6MR1LF3Kpjcu/eG4d9Ue2MPLrR9j5xDr2/3kvu1/u5fX3fDwXl7+woYraxCv4zz3HwOZAy+/Z2s3RbUfZf2yEm794C1WLVubi8vucGrqHPPYeG+SVRJId3YPs7hlk75EhPj6r6jgtPxeX39yC2zwHt7ENahvx4/UFi6uN1fKdSBQnEuOV3qGgsNqwRyKZyovLT48Een4m4+OlMlTXRseNyw+am9tt1zmuUUohLT+rfVa7TtG4fEeCWPtsg/Pw/MbT8rNk/QDjafkw+TZw2eOnU8s/kfOfDj1fyUeNvqIoSoVgjMHXevqKoiiVw5kcvaON0RVFUcLY6J1SlpNBRJpE5GER2WZfG4sclxGR9XZ5MDS+UET+JCLbReTfbRP1CVGjryiKEiIbvVPKcpLcATxqjFkCPGq3C5E0xpxvl+tC458H7jXGLAZ6gfeWctGykHeOPr+Fz3y4l5gjPHq1YecXP8BPbGesZMbQVRPlqmXNLL/5QtpvfAd981fx0x29/PC+Dbzm+htynbHOba0muvNPDPzoEbY+sYH9zxxkx/5+9iTTHE1l+MzVy3KdsdK/f4beTRvp2bSTni099O7oY89Qmu4Rj2OeT/yKt5Np6KQ7E6F7yGN3Xz97Ekl2WgfuwZ4hBo+NMHhshDnnt+V1xoq3NRJpbMVpbCPSPAe/pgG/ahZ+vJ6UE3xZZztjiePiRGM41pmbdeC6VXHcSIy9vclcZ6yBYS9IxEr5NiHLOnI9g+/51M6uzuuMFY+5VFknbtiBmx3zUslccbRCDtzR9aDgWrYz1miXrHwHbuDcHb8oWsGktCKF1cY6cIsVOStGMQduobNMNrnqdDhwlanDnxpH7vXA5Xb9e8DjwO2lvFGCD+8VwDtD7/8s8NWJ3qtP+oqiKGFsyGaJ8k6LiKwLLasncaV2Y8wBu34QaC9yXLU991MicoMdawb6jDHZnxt7gXmlXLQsnvQVRVGmjMll5B4xxlxUbKeIPALMKbDrrvxLGiMipshpFhhj9onI2cBvReQFIFHqDY5Fjb6iKEoIw6mL3jHGXFVsn4gcEpEOY8wBEekADhc5xz77ukNEHgdeA/wEaBCRiH3a7wT2lXJPZWH0U77h7Rd0cP7qN3LPqtW8PJgi7grn1Vdz3uvns+zWNxK9/Ba2mWa+s+kgDz34FHu27CPxymbW/+hOOv0e/I0/58h3fs++P27j4IbDbB9IsX/YY8AL/nPjrrD44FOkHn+G/S9s58jGPfRs66Wne5B9SY/edIZE2iflB1/Ge6rP4lBPml19A+w6OsSO7kH2Hh0i0TfM4LFhkv0pkv39pAcTdFyymJq2RqpamnKJWE59C368Hq96Fn51PUOeYSjlk/Q8q93HENfFDen4TjRGJBYPNP1YHCcaY/eRQUZCRdW80HrG88lkfHz7Wl0bJZan5Y/q+NlCa7HQ4qdTebp99g8hPAbg+xmqIzYhy2r5UcfJ0/HDun6pxdayuFntfgIt/2R197FvP9VF0lTHLxOMwU9NSRmGB4H3AHfb15+NPcBG9AwZY0ZEpAW4DPiC/WXwGHAT8MNi7y+EavqKoihhDPi+X9JyktwNvElEtgFX2W1E5CIR+aY9ZgWwTkQ2AI8BdxtjXrT7bgc+JiLbCTT+b5Vy0bJ40lcURZkqDFNTZdMY0wNcWWB8HXCbXf8DcG6R9+8AVk32umr0FUVRwhjy+jifaZSF0e9YuYCFax/mK+v3E+N+brmwgxU3X0Trje/icOu5/OTlXn7wwCu8vGkDR17exGD3HnwvhRuL0/Djf2Lr717gwLMH2X5gkP3DQUx+xkDMEVqrXNqrIpxVE2XbF7/MkS099O5KsC/p5WLykxmfjPWrxxwh7gq/3HaEHYeDmPwjvUkG+oYZGkgxPJgi1X+U1FACLzlAJjVM8yUX5hqk+DUN+NX1ZKpnkXJiDKZ9hgY9kmlDYiRN/0iGaLwuF5PvVlkNP6Tju7F4rhHKscRIwZj8bKE14xsynofvpWiui+Vi8uNRN0/Hdx3J0/OjTlBwDY6PyYdAx89iMhmqIk7BmPzwdrgRSvhc4xE0UTm+qFohHf9E6pCVGpM/2RyAia6hzGSMlmE4EUTk2yJyWEQ2hsZKSjtWFEWZNiYXp192nE5H7neBa8aMlZp2rCiKMi0YY8ikvJKWcuS0GX1jzJPA0THD1xOkC2Nfb0BRFGVGYaykOfFSjky1pl9q2jE2nXk1wFkdRQ9TFEU5tWjnrNPDBGnHGGPWAGsAauctNZes/haJvS8x8PQa+uav4uEdvfzw8T1s3fQo3dtfZPDwHjKpJG4sTm3rfGZ3LqP9rAZ+/KkP5gqqZUyQ6FMfzTpvIzQvqKdlWTMNSzv52b88VtR5WxcRal2HpphLU8zl63/YnSuoVsh5640k8b0guSn6qr/Cr64nbQuqDaZ9hoZ9kuk0/SmPxLBHYsRjIOXRP+IRq2vMFVQr5Lx1XYdIzCUSdRhIJHPO20wmSMjyM37OeWsymdx9NNVV5RVUG7u4tlhatvOV76WD/4siztvcejg5q4jzNlw0bSIH7tj92eSs8Zy3J/KTNexgPZOct9pY6yQxYDJFTVPZM9VGv6S0Y0VRlOnCYKaqyua0MNUZudm0Y5hE2rCiKMqUYcD4pqSlHDltT/oi8gOCWtEtIrIX+AeCNOMfich7gd3Azafr+oqiKCeCMZBJaXLWpDHG3Fpk13FpxxOR7Osl1n+UeRdeyZVrhd2bH6Jv1wsM9ewPNPPaembNXUTTWYuY09XApUtbuezsZs5tq+V/fHrYJmFFmFsdYV5djKYljTQtbqZpxQLqliwm1rUcv6WLDZ/+Ve6acVeIuw6zIw71UZfWKpdZ9VXUNMepa69l16b9pAcTeTp+Jp3K6edhXbq/cRGDaUMy6TOUTuVp+AMjHsdGPBJDthHKiEe8cU4uKSsSdYnEsjq+bYASdXEiDpGow+FXEqNavr12tlCa8QM937frbbOqRvV7m4wVdRyiruT0fMexr7Yw2ng6fpiaqJtXEC2s44/q7lJUbx5P5xeR0SYqofc7Y46ZLMcVXBvnHKe6+JpzioV31fFPIcaopq8oilJJ+Gr0FUVRKgQN2VQURakcDOCXqZO2FNToK4qihDFGHbnTzZx57fz0Gx/hvPYa6i99P24sTryxnbkXXk37WQ28emkLr1/cwsXzZtM1O0r00FbSL/2C/l9v5Or2WpoX1NO0uJGmFWfRsGwh0a7lSMciMg2d9GYidA957O4dpj7q5CVgNdZGibfUUNdWQ217LfG2RmpaG6jpaKb3GxvyErDGOiLFcXPLlp5hEsOB4zYxEiRgJYbSDAwH6wPD1ok77OGlM9S1tOQlYDmhpCw3IoFz13bA2r1pb14CVnbJZLczo9UxW2dXHZeAFXUDp23UyXa9Gl3PpFO5+UzU7SrqOHkJWOGKmnnjRd4/Hq712I7nuD1RR2sx5606bisXo8lZiqIoFYQafUVRlEpCM3IVRVEqhynKyC2lv4iIvFFE1oeWYRG5we77rojsDO07v5TrlsWTfluym6qP3MJvnznI6z72v/OSrzoiw7gHNpPa8hhHf76FbVv2cGRLDz37B9iX9Fj9bx/OJV95DfPoHvLoHvTY1TvE7p2j3a96e4f5dFdDLvmqpq2OmrZGauY0EW9twmlsI9I8B6ehFT9ez/C/fD7vHsMavhMNOl05kShOJMYfXunNS77KavhDVsP30j5eKpPrdlXfXJNLvsoWWcsmVVVFHOKxSLDtOjzVfzSXfJXV8MNdroIleGppqo7mJV+5Y9YdIdD83dHkrCyFNPjwWMTNT75yZFS/DydtFTvXeDjka+/HJVVN6myh941zzuOOneS5T7WGH0b1/NOLYcri9LP9Re4WkTvs9u1592LMY8D5EHxJANuB34QO+XtjzP2TuWhZGH1FUZQpwxj8qYneuZ6gVA0E/UUeZ4zRH8NNwK+MMUMnc1GVdxRFUUIYEzzpl7KcJCX3F7HcAvxgzNg/icjzInKviFSVclF90lcURRnDJLpitYjIutD2GtsLBAAReQSYU+B9d+Vdb4L+IrYU/bnA2tDwnQRfFjGC3iO3A/840Q2XhdHft7ePr+99ibgrPHq1YWTzQxz94VZ6Nu/l5S09dB8c4OBwhiMpjwHPJxn6Bt746neysy/J7q1D7Ojeyu4jgyT6hhk8NkyyP8Xw4FCucNpFH76SeHsrbmMrbmNbTr/34/X4VbMY8IXBtGEo7eNEYgX1eycaIxILiqU5kRhuVZzHNh8uqt97qaD5SbgJyooL5hKLONTEXGIRN6ffZzX9cOOT1GACOF6/D+v6EDRAaYxH8/T7qOPkmp0Uan4ykaYfJuZkG5zk6/fZn5KFGqCUiht609i3n0w8fbH3qmRe4ZhJPcUfMcZcVPxU5qpi+0RkMv1FbgYeMMakQ+fO/koYEZHvAJ8o5YZV3lEURQlj4/RLWU6SyfQXuZUx0o79okCCJ6obgI2lXLQsnvQVRVGmCsOUFVwr2F9ERC4C3meMuc1udwHzgSfGvP8+EWkl+HG6HnhfKRdVo68oihLGGDKp02/0jTE9FOgvYoxZB9wW2t4FzCtw3BUncl01+oqiKCGMAd9oGYZppXV2FZ/8L6+jaUUX96xaTW86w4Dnk7IZca4EjsS6iMPc6ihNMYfWqgg1TXFu+z9/ZKh/hJHBgcBhO5jAGx7E91J4I8lcdymAWX91N5nq2QykfQbTPknPJ5n2SRz1SIz0MzBiO16NeMyau8g6cGO4sbh14FaFulq5ueJor+zoJWMdtV4qgzEm1+lqbJcr42c4Z96KvO5WuSVUJC3qOLgC3vAgkO+whcJdrhrj0YIO27GF0UpJojq+4Fr2HPkO22KdriaDUNjpeiLdssaet1S0YFplkVGjryiKUhkY4Ayut6ZGX1EUZSz6pK8oilIh+IacdHwmUhZG3z/rbJ766y+w8+gQMe5nUW2UppjLrOYaalri1LbXUts2i5o5zdS0NRJrbsJt7sBtbGXrbT/NafZhcsXRbAKVG4lx/84UiZGDgXZvC6QlkmmSKY/+YY9kKMFqzrKVOc0+2/DEce22bXCSTaZ6cu3zeZp9oQJp4WSq5R2zcpp9xA1eAy1/dD1bLC3rlxhLobHZVZE8zT5bIG1sg5Osfj2ZwmgRV4o2OTnZhiTumBOc6gYnwTlVs1dGUXlHURSlQjAYlXcURVEqBXXkKoqiVBhq9KeZbbsP8bcf+p/46RQDT6+B2sagCFr1bNKROENpn6Rn6Ev77EtlSIx4JIbTDKQyxBvbjyuE5lYFr5FYNNDjbWz9vQ++aIuh5RdA8zM+Gc8L9HgbV3/1tRfkYufHFkHLxdi7DlFHeOj7O/MKoYW18kJx9UuaascthBZuVpJJJUv6NzR+hrpYoLqPLYIGhePqJ0OsBN39ROPqww1ZTiWT0fFVo68cjNHoHUVRlIrBoNE7iqIoFYNq+oqiKBWGyjuKoigVQqDpT/ddnD7Kwui7sWraVl6GG3G4cq3gpY7ipbttolSGjGfwPT/Xjcr4hozn4Xsp3vzO/2Cdqy7xqJvXfWpsQbNP/8N3Q0lSfsHuU1luvfA6HOE4R2shx+tw4kjufaUkPJ1VH7S6LKX71GQSqGqjwZkK+SRPNuEp6uaf4FT6Pd3T5EVV56xSDH3SVxRFqRAMMCUtVKYJNfqKoighDEajdxRFUSqFIHpHjf60cs6CJn7/pbcBUH/p+yf13u9+7e0lH/ux7j0lH3vZ/FklH1uo4Nt4tNWenv+WmuiJtjGZmMjpqIJmUe1dmVLOcEfu6bMC4yAi14jIVhHZLiJ3TMc9KIqiFCL7pF/KcjKIyNtFZJOI+LYZerHjCtpLEVkoIn+y4/8uIrFSrjvlRl9EXOArwFuAlcCtIrJyqu9DURSlGBlT2nKSbARuBJ4sdsAE9vLzwL3GmMVAL/DeUi46HU/6q4DtxpgdxpgU8EPg+mm4D0VRlOPwCcowlLKcDMaYzcaYrRMcVtBeShC/fQVwvz3ue8ANpVxXzBQ7LETkJuAaY8xtdvvdwCXGmA+OOW41sNpunkPwrXim0AIcmfCo8uFMmw+ceXOqpPksMMa0nuiJReTX9vylUA0Mh7bXGGPWTPJ6jwOfMMasK7CvoL0EPgs8ZZ/yEZH5wK+MMedMdL0Z68i1/3BrAERknTGmqOZVbuh8Zj5n2px0PqVjjLnmVJ1LRB4B5hTYdZcx5men6jqTYTqM/j5gfmi7044piqKcURhjrjrJUxSzlz1Ag4hEjDEek7Cj06Hp/xlYYj3PMeAW4MFpuA9FUZSZTkF7aQJd/jHgJnvce4CSfjlMudG330ofBNYCm4EfGWM2TfC2SWlkZYDOZ+Zzps1J5zPDEJH/KCJ7gUuBX4rIWjs+V0Qeggnt5e3Ax0RkO9AMfKuk6061I1dRFEWZPqYlOUtRFEWZHtToK4qiVBAz2uiXa7kGEfm2iBwWkY2hsSYReVhEttnXRjsuIvIlO8fnReSC6bvzwojIfBF5TERetGnjH7HjZTknEakWkadFZIOdz+fseMG0dhGpstvb7f6u6bz/YoiIKyLPicgv7Ha5z2eXiLwgIutFZJ0dK8vP3Exixhr9Mi/X8F1gbKzvHcCjxpglwKN2G4L5LbHLauCrU3SPk8EDPm6MWQm8FviA/b8o1zmNAFcYY84DzgeuEZHXUjyt/b1Arx2/1x43E/kIgbMvS7nPB+CNxpjzQzH55fqZmzkYY2bkQuDRXhvavhO4c7rvaxL33wVsDG1vBTrsegew1a5/Hbi10HEzdSEIDXvTmTAnoAZ4liDL8QgQseO5zx9B5MSldj1ij5Ppvvcx8+gkMIJXAL8gaF5WtvOx97YLaBkzVvafueleZuyTPjAPCNc63mvHypV2Y8wBu34QaLfrZTVPKwW8BvgTZTwnK4WsBw4DDwMvA30mCJGD/HvOzcfuTxCEyM0kvgh8ktGmT82U93wgKHj5GxF5xpZlgTL+zM0UZmwZhjMZY4wRkbKLlRWROuAnwEeNMcckVOi+3OZkjMkA54tIA/AAsHyab+mEEZG3AYeNMc+IyOXTfT+nkL8wxuwTkTbgYRHZEt5Zbp+5mcJMftI/08o1HBKRDgD7etiOl8U8RSRKYPDvM8b81A6X9ZwAjDF9BJmNl2LT2u2u8D3n5mP31xOkwc8ULgOuE5FdBFUYrwD+F+U7HwCMMfvs62GCL+ZVnAGfuelmJhv9M61cw4MEqdKQnzL9IPDXNvrgtUAi9PN1RiDBI/23gM3GmHtCu8pyTiLSap/wEZE4gX9iM8XT2sPzvAn4rbHC8UzAGHOnMabTGNNF8HfyW2PMuyjT+QCISK2IzMquA28mqLRblp+5GcV0OxXGW4C3Ai8R6K13Tff9TOK+fwAcANIE2uJ7CTTTR4FtwCNAkz1WCKKUXgZeAC6a7vsvMJ+/INBXnwfW2+Wt5Ton4NXAc3Y+G4HP2PGzgaeB7cCPgSo7Xm23t9v9Z0/3HMaZ2+XAL8p9PvbeN9hlU/bvv1w/czNp0TIMiqIoFcRMlncURVGUU4wafUVRlApCjb6iKEoFoUZfURSlglCjryiKUkGo0VemHRHJ2EqKm2zly4+LyAl/NkXkU6H1LglVO1WUSkeNvjITSJqgkuKrCBKl3gL8w0mc71MTH6IolYkafWVGYYKU+9XAB212pSsi/ywif7Z10v8OQEQuF5EnReSXEvRc+JqIOCJyNxC3vxzus6d1ReQb9pfEb2wWrqJUJGr0lRmHMWYH4AJtBNnMCWPMxcDFwN+KyEJ76CrgQwT9FhYBNxpj7mD0l8O77HFLgK/YXxJ9wH+autkoysxCjb4y03kzQU2V9QTlnJsJjDjA08aYHSaomPkDgnIRhdhpjFlv158h6HWgKBWJllZWZhwicjaQIaigKMCHjDFrxxxzOUE9oDDFaoqMhNYzgMo7SsWiT/rKjEJEWoGvAV82QWGotcB/taWdEZGltuoiwCpbhdUB3gH8zo6ns8cripKPPukrM4G4lW+iBP14/y+QLeH8TQI55llb4rkbuMHu+zPwZWAxQRnhB+z4GuB5EXkWuGsqJqAo5YJW2VTKEivvfMIY87bpvhdFKSdU3lEURakg9ElfURSlgtAnfUVRlApCjb6iKEoFoUZfURSlglCjryiKUkGo0VcURakg/j+7fyjNRp+DjgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qkoAG591_1k"
      },
      "source": [
        "# Masking\n",
        "# The mask indicates where pad value 0 is present, it outputs a 1 at thoese\n",
        "# locations. Otherwise 0.\n",
        "def create_padding_mask(seq):\n",
        "  # tf.math.equal(x, y): Returns the truth value of (x == y) element-wise.\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding to the attention logits\n",
        "  # returned shape: (batch_size, 1, 1, seq_len)\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K269HHP94SDN",
        "outputId": "e79447b2-09e0-4763-a1d2-b48abd702842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 0], [1, 2, 3, 0, 0], [4, 5, 9, 10, 0]])\n",
        "print(\"shape of x:\", x.shape)\n",
        "create_padding_mask(x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x: (3, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 1., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 1.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB6nXlps5sDX"
      },
      "source": [
        "def create_look_ahead_mask(seq_len):\n",
        "  \"\"\"\n",
        "  tf.linalg.band_part(input, num_lower, num_upper) \n",
        "  ([used to be]tf.matrix_band_part)\n",
        "  (e.g) tf.linalg.band_part(tf.ones((3, 3)), -1, 0)\n",
        "  <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
        "  array([[1., 0., 0.],\n",
        "         [1., 1., 0.],\n",
        "         [1., 1., 1.]], dtype=float32)>\n",
        "  [reference]https://dev.classmethod.jp/articles/tensorflow-matrixbandpart/\n",
        "  \"\"\"\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  # returned shape: (seq_len, seq_len)\n",
        "  return mask"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmkdc3LnbS8Q",
        "outputId": "0ac82292-39dd-41d7-c18e-773d9375a591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "tf.linalg.band_part(tf.ones((3, 3)), -1, 0)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 0., 0.],\n",
              "       [1., 1., 0.],\n",
              "       [1., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgDVySFTehPK"
      },
      "source": [
        "# Scaled Dot-Product Attention\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be boradcastable for addition.\n",
        "  Padding is used for self-attention and encoder-decoder attention.\n",
        "  Look ahead is used for encoder-decoder attention.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "      to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  # shape: (..., seq_len_q, seq_len_k)\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if not mask:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  # As the softmax normalization is done on k, its values decide the amount of \n",
        "  # importance given to Q.\n",
        "  # shape: (..., seq_len_q, seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "  # shape: (..., seq_len_q, depth_v)\n",
        "  output = tf.matmul(attention_weights, v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fz5EHVjnWM2"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(q, k, v, 0)\n",
        "  print(\"Attention weights are:\")\n",
        "  print(temp_attn)\n",
        "  print(\"Output is:\")\n",
        "  print(temp_out)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWp5tKKntb-0"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# shape: (4, 3)\n",
        "temp_k = tf.constant([[10, 0, 0],\n",
        "                      [0, 10, 0],\n",
        "                      [0, 0, 10],\n",
        "                      [0, 0, 10]], dtype=tf.float32)\n",
        "# shape: (4, 2) \n",
        "temp_v = tf.constant([[1, 0],\n",
        "                      [10, 0],\n",
        "                      [100, 5],\n",
        "                      [1000, 6]], dtype=tf.float32)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7vHosjcv9l2",
        "outputId": "8565fe0a-72a4-4b5d-a2aa-0f34a44c7762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# This `query` aligns with the second `key`,\n",
        "# so the second 'value' is returned.\n",
        "# shape: (1, 3)\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-M_Gs_1wldu",
        "outputId": "f7481ae7-cb93-400a-cdf2-5e1186c799ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# This query aligns with a repeated key (third and fourth),\n",
        "# so all associated values get averaged.\n",
        "# shape: (1, 3)\n",
        "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIczBwqyw_5H",
        "outputId": "05586447-37c2-41a6-a0d9-e22a5b6633a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# this query aligns equally with the first and second key,\n",
        "# so their values get averaged.\n",
        "# shape: (1, 3)\n",
        "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcdHpvo5xQGS",
        "outputId": "e049af4c-bff1-4297-ea27-618000e1a552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "temp_q = tf.constant([[2, 3, 5]], dtype=tf.float32)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0.00000002 0.00000483 0.49999762 0.49999762]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[549.99744    5.499974]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H36JESPzxuQZ",
        "outputId": "903ad774-b56b-4e7a-b0a9-f95174d8585c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# pass all the query together\n",
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0], [2, 3, 5]], dtype=tf.float32)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor(\n",
            "[[0.         0.         0.5        0.5       ]\n",
            " [0.         1.         0.         0.        ]\n",
            " [0.5        0.5        0.         0.        ]\n",
            " [0.00000002 0.00000483 0.49999762 0.49999762]], shape=(4, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor(\n",
            "[[550.         5.5     ]\n",
            " [ 10.         0.      ]\n",
            " [  5.5        0.      ]\n",
            " [549.99744    5.499974]], shape=(4, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdGr2tCm2ov6"
      },
      "source": [
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is \n",
        "    (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    # all shapes: (batch_size, seq_len, d_model)\n",
        "    q = self.wq(q)\n",
        "    k = self.wk(k)\n",
        "    v = self.wv(v)\n",
        "\n",
        "    # all shapes: (batch_size, num_heads, seq_len, depth)\n",
        "    q = self.split_heads(q, batch_size)\n",
        "    k = self.split_heads(k, batch_size)\n",
        "    v = self.split_heads(v, batch_size)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len, seq_len)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(q, \n",
        "                                                                       k, \n",
        "                                                                       v, \n",
        "                                                                       mask)\n",
        "    # shape: (batch_size, seq_len, num_heads, depth)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    # shape: (batch_size, seq_len, d_model)\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "    # shape: (batch_size, seq_len, d_model)\n",
        "    output = self.dense(concat_attention)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P85WoWW9_Ei_",
        "outputId": "c3b0325e-bb45-46c3-f101-2a9d2b523426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "# shape: (batch_size, seq_len, d_model)\n",
        "y = tf.random.uniform((1, 60, 512))\n",
        "out, attn = temp_mha(v=y, k=y, q=y, mask=0)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPW4_WxlAE54"
      },
      "source": [
        "# Point-Wise Feed-Forward Network\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([tf.keras.layers.Dense(dff, \n",
        "                                                    activation=\"relu\"), #(batch_size, seq_len, dff)\n",
        "                              tf.keras.layers.Dense(d_model)]) # (batch_size, seq_len, d_model)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCWt_E7cCBLh",
        "outputId": "9a172a0e-d9df-4388-870c-e3ec45dcd44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMtGI55FCVW2"
      },
      "source": [
        "# Encoder Layer\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    # point_wise_feed_forward_netowork is a function\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \"\"\"\n",
        "    tf.keras.layers.Dropout(rate):\n",
        "    rate: Float between 0 and 1. Fraction of the input units to drop.\n",
        "    The Dropout layer randomly sets input units to 0 with a frequency of rate \n",
        "    at each step during training time, which helps prevent overfitting. \n",
        "    Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over \n",
        "    all inputs is unchanged.\"\"\"\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "    # shape: (batch_size, input_seq_len, d_model)\n",
        "    atten_output, _ = self.mha(x, x, x, mask)\n",
        "    atten_output = self.dropout1(atten_output, training=training)\n",
        "    # shape: (batch_size, input_seq_len, d_model)\n",
        "    out1 = self.layernorm1(x + atten_output)\n",
        "\n",
        "    # shape: (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.ffn(out1)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    # shape: (batch_size, input_seq_len, d_model)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "    return out2"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RKuuKeH-MFF",
        "outputId": "4c83d6d0-5736-42b2-cc94-675559193dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "sample_encoder_layer_output = sample_encoder_layer(x=tf.random.uniform((64, 43, 512)), \n",
        "                                                   training=False,\n",
        "                                                   mask=0)\n",
        "sample_encoder_layer_output.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri_3xsrA_FTA"
      },
      "source": [
        "# Decoder Layer\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "    # shape: (batch_size, target_seq_len, d_model)\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(x + attn1)\n",
        "    # shape: (batch_size, target_seq_len, d_model)\n",
        "    attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    # shape: (batch_size, target_seq_len, d_model)\n",
        "    out2 = self.layernorm2(out1 + attn2)\n",
        "\n",
        "    # shape: (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.ffn(out2)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(out2 + ffn_output)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVYpMEdxHe8J",
        "outputId": "a0b0f2f8-8ff1-4e3f-cec7-327481fa081b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(tf.random.uniform((64, 50, 512)),\n",
        "                                                         sample_encoder_layer_output,\n",
        "                                                         training=False,\n",
        "                                                         look_ahead_mask=0,\n",
        "                                                         padding_mask=0)\n",
        "sample_decoder_layer_output.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBGkkj6lIK7W"
      },
      "source": [
        "# Encoder part\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, \n",
        "               num_layers, \n",
        "               d_model, \n",
        "               num_heads, \n",
        "               dff, \n",
        "               input_vocab_size, \n",
        "               maximum_position_encoding, \n",
        "               rate=0.1):\n",
        "    \n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    # shape: (batch_size, input_seq_len, d_model)\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "      \n",
        "    # shape: (batch_size, input_seq_len, d_model)\n",
        "    return x"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0ld222Q56gB",
        "outputId": "ffb23061-6964-49f8-eff3-2e233eff4c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, \n",
        "                         d_model=512, \n",
        "                         num_heads=8, \n",
        "                         dff=2048, \n",
        "                         input_vocab_size=8500, \n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=0)\n",
        "print(sample_encoder_output.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 62, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rZ4w2bu7Dpf"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, \n",
        "               num_layers, \n",
        "               d_model, \n",
        "               num_heads, \n",
        "               dff, \n",
        "               target_vocab_size, \n",
        "               maximum_position_encoding, \n",
        "               rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                                    for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    # shape: (batch_size, target_seq_len, d_model)\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x,\n",
        "                                             enc_output,\n",
        "                                             training,\n",
        "                                             look_ahead_mask,\n",
        "                                             padding_mask)\n",
        "      \n",
        "      attention_weights[\"decoder_layer{}_block1\".format(i+1)] = block1\n",
        "      attention_weights[\"decoder_layer{}_block2\".format(i+1)] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXcYiGsICLGP",
        "outputId": "3567c7a9-058a-4d45-ad36-b5d687807fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, \n",
        "                         d_model=512, \n",
        "                         num_heads=8, \n",
        "                         dff=2048, \n",
        "                         target_vocab_size=8000, \n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                           enc_output=sample_encoder_output,\n",
        "                           training=False,\n",
        "                           look_ahead_mask=0,\n",
        "                           padding_mask=0)\n",
        "# shape: (batch_size, target_seq_len, d_model)\n",
        "print(output.shape) \n",
        "# shape: (batch_size, num_heads, target_seq_len, input_seq_len)\n",
        "print(attn[\"decoder_layer2_block2\"].shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 26, 512)\n",
            "(64, 8, 26, 62)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU4G_fVAEZp8"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, \n",
        "               num_layers, \n",
        "               d_model, \n",
        "               num_heads, \n",
        "               dff, \n",
        "               input_vocab_size, \n",
        "               target_vocab_size, \n",
        "               pe_input, pe_target, \n",
        "               rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "    self.encoder = Encoder(num_layers, \n",
        "                           d_model, \n",
        "                           num_heads, \n",
        "                           dff, \n",
        "                           input_vocab_size, \n",
        "                           pe_input, \n",
        "                           rate)\n",
        "    self.decoder = Decoder(num_layers, \n",
        "                           d_model, \n",
        "                           num_heads, \n",
        "                           dff, \n",
        "                           target_vocab_size, \n",
        "                           pe_target, \n",
        "                           rate)\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self,\n",
        "           inp,\n",
        "           tar,\n",
        "           training,\n",
        "           enc_padding_mask,\n",
        "           look_ahead_mask,\n",
        "           dec_padding_mask):\n",
        "    # shape: (batch_size, inp_seq_len, d_model)\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "    # shape: (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(tar,\n",
        "                                                 enc_output,\n",
        "                                                 training,\n",
        "                                                 look_ahead_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    # shape: (batch_size, tar_seq_len, target_vocab_size)\n",
        "    final_output = self.final_layer(dec_output)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKxxYjdvaFEs",
        "outputId": "04c4f001-fbb2-4bc1-e3a0-226939db4d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_transformer = Transformer(num_layers=2,\n",
        "                                 d_model=512,\n",
        "                                 num_heads=8,\n",
        "                                 dff=2048,\n",
        "                                 input_vocab_size=8500,\n",
        "                                 target_vocab_size=8000,\n",
        "                                 pe_input=10000,\n",
        "                                 pe_target=6000)\n",
        "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
        "fn_out, _ = sample_transformer(temp_input,\n",
        "                               temp_target,\n",
        "                               training=False,\n",
        "                               enc_padding_mask=0,\n",
        "                               look_ahead_mask=0,\n",
        "                               dec_padding_mask=0)\n",
        "fn_out.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 36, 8000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7b28AstbNcE"
      },
      "source": [
        "# Hyperparameters\n",
        "num_layers = 6\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "num_heads = 8\n",
        "vocab_size = 8000\n",
        "\n",
        "input_vocab_size = vocab_size + 2\n",
        "target_vocab_size = vocab_size + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TbhTcMLcgfR"
      },
      "source": [
        "# optimizer scheduler\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "  \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Zj5QxmNiA5"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EkbWNGIN_mZ",
        "outputId": "16735eaf-f4dd-49fc-9943-b698d520093d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(80000, dtype=tf.float32)))\n",
        "plt.title(\"Learning Rate Schecule\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBAf5r0NOh6H"
      },
      "source": [
        "# Loss and Metrics\n",
        "# reduction value \"none\" has to start with lower case letter\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                            reduction=\"none\")\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZECIqzBSZj5",
        "outputId": "7c0d9680-d6aa-41c6-81d4-05068f65517b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample_real = tf.constant([1, 2])\n",
        "sample_pred = tf.constant([[0.7, 11, 0.9],\n",
        "                           [2,5,7]])\n",
        "print(loss_function(sample_real, sample_pred))\n",
        "\n",
        "sample_real = tf.constant([1, 2, 0])\n",
        "sample_pred = tf.constant([[0.7, 11, 0.9],\n",
        "                           [2,5,7],\n",
        "                           [100, 11, 120]])\n",
        "print(loss_function(sample_real, sample_pred))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.066460006, shape=(), dtype=float32)\n",
            "tf.Tensor(0.066460006, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTlg19jpRXhj"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiRzml0bSYX4"
      },
      "source": [
        "# Training and Checkpointing\n",
        "transformer = Transformer(num_layers,\n",
        "                          d_model,\n",
        "                          num_heads,\n",
        "                          dff,\n",
        "                          input_vocab_size,\n",
        "                          target_vocab_size,\n",
        "                          pe_input=input_vocab_size,\n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)\n",
        "\n",
        "def create_masks(inp, tar):\n",
        "  # Encode padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # this padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  \"\"\"tf.(math.)maximumx: it returns element-wise maximum\n",
        "     >>> x= tf.constant([1, 1, 1, 0])\n",
        "     >>> y = tf.constant([1, 0, 0, 0])\n",
        "     >>> tf.math.maximum(x, y)\n",
        "     <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 1, 1, 0], dtype=int32)>\n",
        "  \"\"\"\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask\n",
        "\n",
        "checkpoint_path = \"./checkpoints/train\"\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, \n",
        "                                          checkpoint_path,\n",
        "                                          max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print(\"Latest checkpoint restored!\")\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "                        tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "                        tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp,\n",
        "                                 tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WiXmr3-soku"
      },
      "source": [
        "# Training part\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp: Japanese, tar: English\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(epoch+1,\n",
        "                                                                   batch,\n",
        "                                                                   train_loss.result(),\n",
        "                                                                   train_accuracy.result()))\n",
        "    \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(\"Saving checkpoint for epoch {} at {}\".format(epoch+1,\n",
        "                                                        ckpt_save_path))\n",
        "  \n",
        "  print(\"Epoch {} Loss {:.4f} Accuracy {:.4f}\".format(epoch+1,\n",
        "                                                      train_loss.result(),\n",
        "                                                      train_accuracy.result()))\n",
        "  \n",
        "  print(\"Time taken for 1 epoch: {} secs\\n\".format(time.time - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtdEmLL6zMOP"
      },
      "source": [
        "# Evaluation part\n",
        "def evaluate(inp_sentence):\n",
        "  # inp sentence is Japanese, hence adding the start and end token\n",
        "  jpn_start_token = [jpn_sp.PieceToId(\"<s>\")]\n",
        "  jpn_end_token = [jpn_sp.PieceToId(\"</s>\")]\n",
        "  inp_sentence = jpn_start_token + jpn_sp.EncodeAsIds(inp_sentence) + jpn_end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "  # as the target is English, the first word to the transformer should be the\n",
        "  # English start token\n",
        "  decoder_input = [en_sp.PieceToId(\"<s>\")]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "  for i in range(EN_MAX_LEN):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input,\n",
        "                                                                     output)\n",
        "    \n",
        "    # predictions.shape: (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "    # shape: (batch_size, 1, vocab_size)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == en_sp.PieceToId(\"</s>\"):\n",
        "      # tf.squeeze: Removes dimensions of size 1 from the shape of a tensor.\n",
        "      #   axis: If specified, only squeezes the dimensions listed. \n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "    # concatenate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "  \n",
        "  return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "  sentence = jpn_sp.EncodeAsIds(sentence)\n",
        "  attention = tf.squeeze(attention[layer], axis=0)\n",
        "\n",
        "  for head in range(attention.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head+1)\n",
        "\n",
        "    # plot the attention weights\n",
        "    ax.matshow(attention[head][:-1, :], cmap=\"viridis\")\n",
        "    fontdict = {\"fontsize\": 10}\n",
        "    ax.set_xticks(range(len(sentence)+2))\n",
        "    ax.set_yticks(range(len(result)))\n",
        "    ax.set_ylim(len(result)-1.5, -0.5)\n",
        "    ax.set_xticklabels([\"<s>\"] + [jpn_sp.decode([i]) for i in sentence] + [\"</s>\"],\n",
        "                       fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([en_sp.decode([i]) for i in result if i != en_sp.PieceToId(\"</s>\")],\n",
        "                       fontdict=fontdict)\n",
        "    ax.set_xlabel(\"Head {}\".format(head+1))\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "def translate(sentence, plot=\"\"):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  predicted_sentence = en_sp.decode([i for i in result if i != en_sp.PieceToId(\"</s>\")])\n",
        "\n",
        "  print(\"Input: {}\".format(sentence))\n",
        "  print(\"Predicted translation: {}\".format(predicted_sentence))\n",
        "\n",
        "  if plot:\n",
        "    plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOzCDwBb0w7g",
        "outputId": "fd944446-9e9e-4b60-c5d7-ee102561d413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "t = tf.reshape(tf.range(6), [1, 2, 1, 3, 1, 1])\n",
        "print(tf.shape(t))\n",
        "print(tf.shape(tf.squeeze(t)))\n",
        "# axis: If specified, only squeezes the dimensions listed. \n",
        "print(tf.shape(tf.squeeze(t, [2, 4])))\n",
        "print(tf.squeeze(t, [2, 4]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1 2 1 3 1 1], shape=(6,), dtype=int32)\n",
            "tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
            "tf.Tensor([1 2 3 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[[[0]\n",
            "   [1]\n",
            "   [2]]\n",
            "\n",
            "  [[3]\n",
            "   [4]\n",
            "   [5]]]], shape=(1, 2, 3, 1), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6LJWd7A034W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}